<!doctype html>
<html>
    <head>
                <title>random wandering - FlowMRI</title>

            <meta charset="utf-8">
            <meta http-equiv="X-UA-Compatible" content="IE=edge">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">

            
            <link rel="canonical" href="https://evelyn92.github.io/FlowMRI/nav/random_thoughts/">
            

            
                <link  rel="icon" type="image/x-icon" href="../../assets/favicon.ico">
            
                    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
                        <script>hljs.initHighlightingOnLoad();</script>
            <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700">
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
            <link rel="stylesheet" href="../../assets/css/bootstrap.min.css">
            <link rel="stylesheet" href="../../assets/css/main.min.css">
                <link href="../../stylesheets/extra.css" rel="stylesheet">
                <script src="../../search/main.js"></script>

            
                
            
    </head>

    <body>
        <div class="container py-3">
            <header>
                    <!-- block header -->
<nav class="navbar navbar-expand-xl border-bottom">
    <div class="container-fluid">
        
            <img class="logo" src="../../assets/logo.png">
        

        
            <span class="normal fs-4 title-color site-name" id="component-site-name" style="text-transform: uppercase;">FlowMRI</span>
        

        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarsMenu"
            aria-controls="navbarsMenu" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse flex-column ml-auto" id="navbarsMenu">
            <ul class="navbar-nav">

                <!-- block menu -->
                <li class="nav-item">
                    <!-- block menu -->
    
        <li class="nav-item" id="component-menu">
            <ul class="navbar-nav">
                        <li class="nav-item">
                            <a class="
                            nav-link text-gray text-decoration-none" href="../..">[Home]</a>
                        </li>
                        <li class="nav-item">
                            <a class="
                            nav-link text-gray text-decoration-none" href="../yiwei_cv/">[About me]</a>
                        </li>
                        <li class="nav-item dropdown">
                            <a class="
                            nav-link dropdown-toggle text-decoration-none" href="#" data-bs-toggle="dropdown">[Artifacts]</a>
                            <ul class="dropdown-menu">
                                    <!-- block dropdown-menu -->
    <li>
        <a href="../papers/adaptive_bulk_motion/" class="dropdown-item text-decoration-none ">bulk motion</a>
    </li>
<!-- endblock -->
                                    <!-- block dropdown-menu -->
    <li>
        <a href="../papers/retrospective_correction/" class="dropdown-item text-decoration-none ">head motion</a>
    </li>
<!-- endblock -->
                                    <!-- block dropdown-menu -->
    <li>
        <a href="../papers/SISMIK_for_brain_MRI/" class="dropdown-item text-decoration-none ">SISMIK DL motion</a>
    </li>
<!-- endblock -->
                            </ul>
                        </li>
                        <li class="nav-item dropdown">
                            <a class="
                            nav-link dropdown-toggle text-decoration-none" href="#" data-bs-toggle="dropdown">[Sequences]</a>
                            <ul class="dropdown-menu">
                                    <!-- block dropdown-menu -->
    <li>
        <a href="../" class="dropdown-item text-decoration-none ">None</a>
    </li>
<!-- endblock -->
                            </ul>
                        </li>
                        <li class="nav-item dropdown">
                            <a class=" active 
                            nav-link dropdown-toggle text-decoration-none" href="#" data-bs-toggle="dropdown">[Thought wandering]</a>
                            <ul class="dropdown-menu">
                                    <!-- block dropdown-menu -->
    <li>
        <a href="./" class="dropdown-item text-decoration-none  active ">random wandering</a>
    </li>
<!-- endblock -->
                            </ul>
                        </li>
            </ul>
        </li>
<!-- endblock -->
                </li>
                <!-- endblock -->

                <!-- block search -->
                <li class="nav-item">
                    <a class="collapsed" data-bs-toggle="collapse" href="#collapseExample" role="button" aria-expanded="false" aria-controls="collapseExample">
                        <div class="md-search-icon">
                            <i class="fa fa-search" aria-hidden="true"></i>
                        </div>
                    </a>
                </li>
                <!--  endblock -->

                <!-- block source -->
                <li class="nav-item">
                    
                        
                            <!-- block source -->
<div class="md-source source-detail">
  <div class="md-source-repo-icon">
    <i class="fa fa-github-alt" aria-hidden="true"></i>
  </div>

  <div class="md-source-repo-url">
    <a href="https://github.com/Evelyn92/FlowMRI" class="md-source">
      Evelyn92/FlowMRI
    </a>

    <ul class="md-source-repo-text">
      <li>
        <i class="fa fa-tag" aria-hidden="true"></i>
        <img alt="GitHub tag (latest by date)"
          src="https://img.shields.io/github/v/tag/Evelyn92/FlowMRI?color=white&label=%20&style=flat-square">
      </li>

      <li>
        <i class="fa fa-star" aria-hidden="true"></i>
        <img alt="GitHub Repo stars"
          src="https://img.shields.io/github/stars/Evelyn92/FlowMRI?color=white&label=%20&style=flat-square">
      </li>

      <li>
        <i class="fa fa-code-fork" aria-hidden="true"></i>
        <img alt="GitHub forks"
          src="https://img.shields.io/github/forks/Evelyn92/FlowMRI?color=white&label=%20&style=flat-square">
      </li>
    </ul>
  </div>

</div>
<!--  endblock -->
                        
                    
                </li>
                <!--  endblock -->
            </ul>
        </div>
    </div>
</nav>
<!--  endblock -->
            </header>

            <main><!-- block search -->
<div class="collapse" id="collapseExample">
    <div role="search" class="search-box">
        <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
            <input type="text" name="q" class="search-query"
            placeholder="Search docs" title="Type search term here" />
        </form>
    </div>
</div>
<!-- endblock -->
                    <!-- block content -->
<section class="container post">
    <article>
        <header>
            
                <h1 class="normal title" id="component-title">random wandering</h1>
            
        </header>
        <p><p>:paw_prints: Random Question Wandering</p>
<hr />
<h2 id="cherry_blossom-what-is-the-difference-between-si-projection-and-fid">:cherry_blossom: What is the difference between SI-Projection and FID?</h2>
<p>The <strong>SI-projection</strong> and <strong>FID (Free Induction Decay)</strong> are two different concepts in Magnetic Resonance Imaging (MRI) and spectroscopy, though they are related in the context of data acquisition and signal interpretation:</p>
<h3 id="1-free-induction-decay-fid">1. <strong>Free Induction Decay (FID)</strong></h3>
<ul>
<li>
<p><strong>Definition</strong>: FID is the raw signal detected immediately after the RF excitation pulse in MRI or spectroscopy. It represents the decaying sinusoidal signal generated by precessing magnetic moments of nuclei as they return to equilibrium.</p>
</li>
<li>
<p><strong>Characteristics</strong>:</p>
</li>
<li>It is the time-domain signal acquired directly by the receiver coil.</li>
<li>Contains all frequency components of the excited spins.</li>
<li>
<p>The decay is due to <strong>T2* relaxation</strong>, which encompasses both dephasing caused by spin-spin interactions and magnetic field inhomogeneities.</p>
</li>
<li>
<p><strong>Usage</strong>:</p>
</li>
<li>In spectroscopy, FID is Fourier transformed to extract the frequency-domain spectrum.</li>
<li>In imaging, FID can be sampled to generate k-space data, which is later transformed into an image.</li>
</ul>
<hr />
<h3 id="2-si-projection-superior-inferior-projection">2. <strong>SI-Projection (Superior-Inferior Projection)</strong></h3>
<ul>
<li>
<p><strong>Definition</strong>: SI-projection refers to a 1D or reduced-dimensionality representation of the MRI signal along the superior-inferior (head-to-foot) anatomical direction. It can be considered as a summation or integration of the MRI signal over the other spatial dimensions.</p>
</li>
<li>
<p><strong>Characteristics</strong>:</p>
</li>
<li>It's a spatially resolved signal that contains positional information along the superior-inferior axis.</li>
<li>Typically used in projection-based imaging methods or when simplifying multi-dimensional data.</li>
<li>
<p>May be used for quick anatomical localization or as an intermediate step in reconstruction workflows.</p>
</li>
<li>
<p><strong>Usage</strong>:</p>
</li>
<li>In motion-resolved imaging, SI-projections are often used to monitor respiratory or cardiac motion.</li>
<li>For example, signals binned along the SI-axis can capture diaphragm movement during breathing.</li>
</ul>
<hr />
<h3 id="key-differences"><strong>Key Differences</strong></h3>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>FID</th>
<th>SI-Projection</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Nature</strong></td>
<td>Time-domain raw signal</td>
<td>Spatial projection signal</td>
</tr>
<tr>
<td><strong>Dimension</strong></td>
<td>1D (time)</td>
<td>1D (spatial)</td>
</tr>
<tr>
<td><strong>Information Type</strong></td>
<td>Frequency and phase</td>
<td>Spatial (position-based)</td>
</tr>
<tr>
<td><strong>Purpose</strong></td>
<td>Basis for Fourier transforms to generate spectra or k-space</td>
<td>Basis for motion tracking or projection imaging</td>
</tr>
<tr>
<td><strong>Dependence</strong></td>
<td>Purely signal decay (T2*)</td>
<td>Aggregates signal spatially</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="example-in-practice">Example in Practice</h3>
<ol>
<li><strong>FID</strong>:</li>
<li>Directly acquired after the RF pulse.</li>
<li>
<p>Used in spectroscopy or as input for advanced reconstruction techniques in imaging.</p>
</li>
<li>
<p><strong>SI-Projection</strong>:</p>
</li>
<li>Derived from imaging data along the superior-inferior axis.</li>
<li>Often used in motion detection, like tracking respiratory motion during MRI.</li>
</ol>
<hr />
<h2 id="cherry_blossom-ok-then-for-the-raw-data-readouts-from-3d-radial-trajectory-how-can-i-extract-them-respectively">:cherry_blossom: OK, then for the raw data readouts from 3D radial trajectory, how can I extract them respectively?</h2>
<p>Extracting <strong>FID</strong> and <strong>SI-projection</strong> from the raw data acquired using a 3D radial trajectory requires understanding the data's structure and processing steps. Here's how you can approach it:</p>
<hr />
<h3 id="1-understanding-the-raw-data"><strong>1. Understanding the Raw Data</strong></h3>
<ul>
<li><strong>3D Radial Trajectory</strong>: In a 3D radial acquisition, k-space is sampled along radial spokes that span the 3D volume.</li>
<li>Each readout corresponds to a radial trajectory in k-space.</li>
<li>
<p>Data typically includes both real and imaginary parts of the signal for each sampled point.</p>
</li>
<li>
<p><strong>Key Concepts</strong>:</p>
</li>
<li><strong>FID</strong>: The signal along the time dimension for a single trajectory before gridding or Fourier Transform.</li>
<li><strong>SI-Projection</strong>: Data integrated or projected along the superior-inferior axis after some spatial processing.</li>
</ul>
<hr />
<h3 id="2-extracting-fid"><strong>2. Extracting FID</strong></h3>
<p>The <strong>FID</strong> is essentially the raw time-domain signal acquired during each readout, and it can be extracted as follows:</p>
<ol>
<li><strong>Identify the Readout Dimension</strong>:</li>
<li>Locate the time-domain dimension in your raw data array (e.g., <code>[readout, spokes, coils]</code>).</li>
<li>
<p>Each trajectory in k-space corresponds to an FID signal.</p>
</li>
<li>
<p><strong>How to Extract FID:</strong></p>
</li>
<li>
<p>The FID is the very first sample of the raw readout for each spoke and each coil:</p>
<p>```python</p>
<p>fid = raw_data[0, :, coil_index]
<code>``
  -</code>0<code>: Index for the first point in the readout (central k-space).
  -</code>:<code>: All spokes.
  -</code>coil_index`: A specific receive coil.</p>
</li>
</ol>
<hr />
<h3 id="3-extracting-si-projection"><strong>3. Extracting SI-Projection</strong></h3>
<p>The <strong>SI-projection</strong> requires spatial information, so some level of reconstruction or processing is needed:</p>
<ol>
<li><strong>Reconstruct SI Direction</strong>:</li>
<li>Use the radial trajectory information to identify k-space points corresponding to the superior-inferior axis.</li>
<li>
<p>If trajectory data is stored in <code>kx</code>, <code>ky</code>, <code>kz</code> arrays, filter points for the SI-axis (e.g., where <code>kx ≈ ky ≈ 0</code>).</p>
</li>
<li>
<p><strong>Sum or Integrate Data</strong>:</p>
</li>
<li>Aggregate the raw data over the orthogonal dimensions:
     <code>python
     si_projection = raw_data.sum(axis=orthogonal_axes)</code></li>
<li>
<p>For a specific coil:
     <code>python
     si_projection = np.sum(raw_data[:, si_indices, coil_index], axis=1)</code></p>
</li>
<li>
<p><strong>Motion Binning (Optional)</strong>:</p>
</li>
<li>If used for motion analysis, apply respiratory or cardiac binning based on temporal information or physiological signals.</li>
</ol>
<hr />
<h3 id="4-practical-notes"><strong>4. Practical Notes</strong></h3>
<ul>
<li><strong>Trajectory Information</strong>:</li>
<li>
<p>Use the trajectory file (often provided by the scanner) to map k-space points to spatial coordinates.</p>
</li>
<li>
<p><strong>FFT for Image Space</strong>:</p>
</li>
<li>
<p>If you need to convert raw k-space data to image space, perform an FFT on the summed or integrated k-space data along the appropriate dimensions.</p>
</li>
<li>
<p><strong>Coordinate Transformations</strong>:</p>
</li>
<li>Ensure proper scaling and centering of k-space before projection or reconstruction.</li>
</ul>
<hr />
<h2 id="the-suitability-of-their-applications-and-motion-characteristics">The suitability of their applications and motion characteristics</h2>
<p>Both <strong>FID</strong> and <strong>SI-projection</strong> are valuable tools for detecting motion in MRI, but they differ significantly in how they are generated and what types of motion they can capture. Their suitability depends on the specific application and motion characteristics.</p>
<hr />
<h3 id="1-fid-free-induction-decay"><strong>1. FID (Free Induction Decay)</strong></h3>
<h4 id="key-features"><strong>Key Features:</strong></h4>
<ul>
<li><strong>What It Captures</strong>:</li>
<li>The FID is sensitive to <strong>bulk magnetization changes</strong>, such as those caused by large-scale motion, scanner instability, or physiological processes that affect the entire signal simultaneously.</li>
<li>
<p>Captures variations over time at the center of k-space, reflecting the overall signal behavior.</p>
</li>
<li>
<p><strong>How It Works for Motion Detection</strong>:</p>
</li>
<li>Motion affects the uniformity of the magnetic field, causing variations in the FID amplitude or phase.</li>
<li>
<p>Large-scale motion (e.g., head movement) can disrupt the signal decay pattern.</p>
</li>
<li>
<p><strong>Strengths</strong>:</p>
</li>
<li><strong>High sensitivity to gross motion</strong>: Since it captures the central k-space signal, even small deviations in motion can be detected as phase or amplitude variations.</li>
<li><strong>No spatial information required</strong>: FID does not depend on spatial encoding, making it computationally lightweight and simple to analyze.</li>
<li>
<p>Ideal for detecting <strong>global motion patterns</strong>, such as large head movements.</p>
</li>
<li>
<p><strong>Limitations</strong>:</p>
</li>
<li>Lacks spatial specificity: Cannot localize motion along specific axes or regions.</li>
<li>Less effective for subtle, localized motion or small physiological movements (e.g., breathing, eye motion).</li>
</ul>
<hr />
<h3 id="2-si-projection-superior-inferior-projection_1"><strong>2. SI-Projection (Superior-Inferior Projection)</strong></h3>
<h4 id="key-features_1"><strong>Key Features:</strong></h4>
<ul>
<li><strong>What It Captures</strong>:</li>
<li>SI-projection aggregates data along the superior-inferior axis of the body, providing a motion-sensitive signal that captures shifts in this specific spatial direction.</li>
<li>
<p>Reflects changes in signal distribution along the axis, making it more <strong>spatially specific</strong> than FID.</p>
</li>
<li>
<p><strong>How It Works for Motion Detection</strong>:</p>
</li>
<li>Tracks changes in the superior-inferior axis signal due to <strong>respiratory motion</strong>, <strong>cardiac motion</strong>, or localized shifts (e.g., diaphragm or organ movement).</li>
<li>
<p>Useful in motion-binned reconstruction methods to sort data into motion states.</p>
</li>
<li>
<p><strong>Strengths</strong>:</p>
</li>
<li><strong>Direction-specific</strong>: Captures motion primarily along the SI axis, which is beneficial for tracking respiratory motion or vertical head movements.</li>
<li>Allows <strong>motion binning</strong>: By grouping data based on SI-projection values, you can segment the data into different motion states for retrospective correction.</li>
<li>
<p>More sensitive to subtle, periodic physiological motion (e.g., respiration or heartbeat).</p>
</li>
<li>
<p><strong>Limitations</strong>:</p>
</li>
<li>Less sensitive to non-SI motion: Does not effectively capture lateral (left-right) or anterior-posterior movements.</li>
<li>Requires spatial trajectory information, increasing processing complexity compared to FID.</li>
</ul>
<hr />
<h3 id="comparison-table"><strong>Comparison Table</strong></h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th><strong>FID</strong></th>
<th><strong>SI-Projection</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Captures</strong></td>
<td>Global magnetization changes</td>
<td>Localized motion along SI axis</td>
</tr>
<tr>
<td><strong>Spatial Specificity</strong></td>
<td>None (global signal)</td>
<td>High (specific to SI-axis motion)</td>
</tr>
<tr>
<td><strong>Motion Sensitivity</strong></td>
<td>Large-scale, global motion</td>
<td>Subtle, periodic motion (e.g., respiration)</td>
</tr>
<tr>
<td><strong>Computation</strong></td>
<td>Lightweight, no trajectory needed</td>
<td>Requires trajectory, spatial processing</td>
</tr>
<tr>
<td><strong>Best For</strong></td>
<td>Detecting global motion or scanner instabilities</td>
<td>Tracking respiration or periodic SI motion</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="3-which-to-use-when"><strong>3. Which to Use When?</strong></h3>
<ul>
<li><strong>Use FID When</strong>:</li>
<li>The primary concern is <strong>gross motion</strong>, such as patient movement or scanner instabilities.</li>
<li>Simplicity is crucial (no need for spatial information or projections).</li>
<li>
<p>You are monitoring the signal for artifacts in real-time (e.g., during acquisition).</p>
</li>
<li>
<p><strong>Use SI-Projection When</strong>:</p>
</li>
<li>The focus is on <strong>physiological motion</strong> such as respiration or cardiac motion.</li>
<li>You need <strong>motion-resolved reconstructions</strong>, where SI-projections enable binning into different motion states.</li>
<li>Spatial specificity along the superior-inferior axis is necessary (e.g., for organ tracking or respiratory gating).</li>
</ul>
<hr />
<h3 id="practical-applications"><strong>Practical Applications</strong></h3>
<table>
<thead>
<tr>
<th><strong>Application</strong></th>
<th><strong>Preferred Method</strong></th>
<th><strong>Reason</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Head motion detection</strong></td>
<td>FID</td>
<td>Captures global signal disturbances due to head shifts.</td>
</tr>
<tr>
<td><strong>Respiratory gating</strong></td>
<td>SI-Projection</td>
<td>Sensitive to motion along the SI axis (e.g., diaphragm movement).</td>
</tr>
<tr>
<td><strong>Real-time motion artifact monitoring</strong></td>
<td>FID</td>
<td>Simple, computationally efficient, no spatial info needed.</td>
</tr>
<tr>
<td><strong>Cardiac motion tracking</strong></td>
<td>SI-Projection</td>
<td>Captures subtle periodic motion along the SI axis.</td>
</tr>
<tr>
<td><strong>Motion binning</strong></td>
<td>SI-Projection</td>
<td>Enables grouping of data into distinct motion states.</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="4-combining-both"><strong>4. Combining Both</strong></h3>
<p>In some cases, FID and SI-projection can be used <strong>together</strong>:
- Use <strong>FID</strong> to monitor large-scale, abrupt motion (e.g., head movement).
- Use <strong>SI-projection</strong> for subtle, repetitive motion like respiration or cardiac cycles.</p>
<p>By combining these approaches, you can achieve robust motion detection across a wide range of conditions. Let me know if you'd like help implementing this in your dataset!</p>
<h2 id="cherry_blossom-how-can-si-projection-be-used-in-eye-motion-detection">:cherry_blossom: How can SI-projection be used in eye motion detection?</h2>
<p>Using <strong>SI-projection</strong> to monitor <strong>eye motion</strong> can be effective, but its applicability depends on the specific characteristics of the eye motion being studied and how well the motion aligns with the <strong>superior-inferior (SI)</strong> axis. Here's a breakdown:</p>
<hr />
<h3 id="1-eye-motion-characteristics-and-si-projections"><strong>1. Eye Motion Characteristics and SI-Projections</strong></h3>
<ul>
<li><strong>Types of Eye Motion</strong>:</li>
<li><strong>Fixations</strong>: Minimal motion as the gaze focuses on a single point.</li>
<li><strong>Saccades</strong>: Rapid shifts in gaze between fixation points, often multidirectional.</li>
<li><strong>Microsaccades</strong>: Small, involuntary eye movements during fixation.</li>
<li>
<p><strong>Smooth Pursuit</strong>: Continuous tracking of a moving target.</p>
</li>
<li>
<p><strong>Motion Along the SI-Axis</strong>:</p>
</li>
<li>If the primary eye motion occurs along the SI-axis (e.g., vertical saccades), the <strong>SI-projection</strong> would be sensitive to these changes.</li>
<li>For horizontal (left-right) or oblique movements, the SI-projection would capture only a fraction of the overall motion, limiting its utility.</li>
</ul>
<hr />
<h3 id="2-advantages-of-using-si-projection-for-eye-motion"><strong>2. Advantages of Using SI-Projection for Eye Motion</strong></h3>
<ul>
<li><strong>Sensitivity to Vertical Motion</strong>:</li>
<li>Eye movements with a strong vertical component (e.g., vertical saccades, gaze shifts, or blinking) will produce clear variations in the SI-projection.</li>
<li>
<p>Can capture eyelid motion during blinks, as this involves a significant SI-axis component.</p>
</li>
<li>
<p><strong>Low Computational Complexity</strong>:</p>
</li>
<li>
<p>SI-projections aggregate signal along the vertical axis, reducing the dimensionality of data and simplifying analysis.</p>
</li>
<li>
<p><strong>Applications in Eye Motion Studies</strong>:</p>
</li>
<li><strong>Blink Detection</strong>: Blinks primarily involve vertical motion of the eyelids, making SI-projection an effective tool.</li>
<li><strong>Vertical Gaze Tracking</strong>: Changes in vertical eye position can be directly observed in the projection signal.</li>
<li><strong>Motion Binning</strong>: SI-projections can sort data into states of upward, downward, or stationary gaze for further analysis.</li>
</ul>
<hr />
<h3 id="3-challenges-and-limitations"><strong>3. Challenges and Limitations</strong></h3>
<ul>
<li><strong>Reduced Sensitivity to Horizontal or Oblique Motion</strong>:</li>
<li>Eye motion along other axes (e.g., left-right saccades) may not produce significant variations in the SI-projection.</li>
<li>
<p>Combining SI-projection with other projections (e.g., along the left-right or anterior-posterior axis) may be necessary for comprehensive motion tracking.</p>
</li>
<li>
<p><strong>Small Amplitude of Eye Movements</strong>:</p>
</li>
<li>
<p>Eye movements, especially microsaccades or smooth pursuit, generate smaller displacements compared to gross motion (e.g., respiration). This requires high sensitivity in the SI-projection data.</p>
</li>
<li>
<p><strong>Artifact Sensitivity</strong>:</p>
</li>
<li>Noise or signal disturbances unrelated to eye motion (e.g., system vibrations) might interfere with SI-projection signals.</li>
</ul>
<hr />
<h3 id="4-practical-considerations"><strong>4. Practical Considerations</strong></h3>
<p>To use SI-projection for <strong>eye motion detection</strong>, you might follow these steps:</p>
<h4 id="step-1-preprocessing"><strong>Step 1: Preprocessing</strong></h4>
<ul>
<li><strong>Data Source</strong>:</li>
<li>Use raw k-space data or reconstructed signals, ensuring the trajectory is well-sampled.</li>
<li><strong>Trajectory Alignment</strong>:</li>
<li>Verify that the SI-axis in the trajectory corresponds to the physical superior-inferior direction of the eye.</li>
</ul>
<h4 id="step-2-extract-si-projection"><strong>Step 2: Extract SI-Projection</strong></h4>
<ul>
<li>Aggregate k-space data along the SI-axis:
  <code>python
  si_projection = np.sum(raw_data[:, si_indices, :], axis=1)</code></li>
</ul>
<h4 id="step-3-analyze-motion"><strong>Step 3: Analyze Motion</strong></h4>
<ul>
<li>Look for abrupt changes in SI-projection signals to detect vertical saccades or blinks:
  <code>python
  diff_signal = np.diff(si_projection, axis=0)</code></li>
<li>Use thresholds to classify motion events (e.g., saccades, blinks, or fixations).</li>
</ul>
<h4 id="step-4-validate-against-ground-truth"><strong>Step 4: Validate Against Ground Truth</strong></h4>
<ul>
<li>Compare SI-projection results with independent eye-tracking data (e.g., from an EyeLink system) to ensure accuracy.</li>
</ul>
<hr />
<h3 id="5-example-application"><strong>5. Example Application</strong></h3>
<p>Here’s how SI-projection could be applied for a <strong>blink detection</strong> task:</p>
<h4 id="case-blink-detection"><strong>Case: Blink Detection</strong></h4>
<ol>
<li><strong>What Happens During a Blink?</strong></li>
<li>
<p>Eyelid movement occurs along the SI-axis, creating a sharp spike in the SI-projection signal.</p>
</li>
<li>
<p><strong>Signal Extraction</strong>:</p>
</li>
<li>Calculate the SI-projection for each time point.</li>
<li>
<p>Detect peaks or high-amplitude changes that correspond to eyelid motion.</p>
</li>
<li>
<p><strong>Results</strong>:</p>
</li>
<li>The SI-projection provides a time-series representation of eye motion along the SI-axis. Peaks in the signal represent blink events.</li>
</ol>
<hr />
<h3 id="comparison-to-other-techniques"><strong>Comparison to Other Techniques</strong></h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>SI-Projection for Eye Motion</th>
<th>Dedicated Eye-Tracking Systems (e.g., EyeLink)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Sensitivity</strong></td>
<td>High for vertical motion or blinks</td>
<td>High for all types of eye motion</td>
</tr>
<tr>
<td><strong>Spatial Resolution</strong></td>
<td>Limited to the SI-axis</td>
<td>Full 2D/3D tracking of eye position</td>
</tr>
<tr>
<td><strong>Ease of Use</strong></td>
<td>Low computational overhead</td>
<td>Requires dedicated hardware and calibration</td>
</tr>
<tr>
<td><strong>Best Use Case</strong></td>
<td>Blinks, vertical gaze shifts</td>
<td>Saccades, smooth pursuit, and detailed tracking</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="conclusion"><strong>Conclusion</strong></h3>
<p>The <strong>SI-projection</strong> can be a simple, effective tool for detecting <strong>vertical eye motion</strong>, especially blinks and vertical gaze shifts. However, its application is limited to motion along the SI-axis, making it less effective for horizontal or complex multidirectional movements. For comprehensive eye motion analysis, pairing SI-projections with a dedicated eye-tracking system or additional k-space projections would provide better coverage. </p>
<p>Let me know if you'd like help setting up such an analysis pipeline!</p>
<h2 id="cherry_blossom-then-can-i-project-it-alternatively-to-another-direction-say-left-right-projection-instead-of-si-projection">:cherry_blossom: Then can I project it alternatively to another direction, say left-right projection instead of SI-projection.</h2>
<p>Yes, you can project the data along any direction (such as left-right, anterior-posterior, or any oblique direction) instead of the superior-inferior (SI) axis. This involves aggregating the k-space data along the desired direction or axis to extract a corresponding projection. Here's how you can do it step by step:</p>
<hr />
<h3 id="1-concept-of-alternative-projections"><strong>1. Concept of Alternative Projections</strong></h3>
<ul>
<li><strong>Projection Direction</strong>:</li>
<li>
<p>The SI-projection aggregates signal intensity along the superior-inferior axis. Similarly, you can compute a projection along:</p>
<ul>
<li><strong>Left-Right (LR)</strong>: Captures horizontal motion or changes along the x-axis.</li>
<li><strong>Anterior-Posterior (AP)</strong>: Captures depth or forward-backward changes along the y-axis.</li>
<li><strong>Custom/Oblique Directions</strong>: Projects data onto a diagonal or other arbitrary axis.</li>
</ul>
</li>
<li>
<p><strong>Utility</strong>:</p>
</li>
<li>Choose the direction depending on the dominant motion in your data or the type of motion you're studying:<ul>
<li>LR projection is better for <strong>horizontal eye movements</strong> (e.g., horizontal saccades).</li>
<li>AP projection may be relevant for <strong>depth changes</strong> or slight forward/backward tilting.</li>
</ul>
</li>
</ul>
<hr />
<h3 id="2-implementation-steps"><strong>2. Implementation Steps</strong></h3>
<h4 id="step-1-identify-the-desired-axis"><strong>Step 1: Identify the Desired Axis</strong></h4>
<ul>
<li>Identify the direction in k-space that corresponds to the anatomical axis of interest.</li>
<li><strong>Example</strong>:<ul>
<li>SI-axis = Vertical direction = ( z )</li>
<li>LR-axis = Horizontal direction = ( x )</li>
<li>AP-axis = Depth direction = ( y )</li>
</ul>
</li>
</ul>
<h4 id="step-2-aggregate-along-the-selected-axis"><strong>Step 2: Aggregate Along the Selected Axis</strong></h4>
<ul>
<li>
<p>Aggregate the k-space data along the desired axis by summing or integrating the data.
  <code>python
  # Example with numpy arrays
  lr_projection = np.sum(raw_data[:, lr_indices, :], axis=1)
  ap_projection = np.sum(raw_data[:, ap_indices, :], axis=1)</code></p>
</li>
<li>
<p>If using Cartesian indices, you can specify which slices or indices correspond to the axis of interest.</p>
</li>
</ul>
<h4 id="step-3-visualize-or-analyze-the-projection"><strong>Step 3: Visualize or Analyze the Projection</strong></h4>
<ul>
<li>The resulting 1D projection will represent signal variations over time along the chosen axis.</li>
<li>For motion detection:</li>
<li>Look for changes or peaks in the projection signal.</li>
<li>Use thresholds or derivatives to classify motion events.</li>
</ul>
<h4 id="step-4-validate-against-the-si-projection"><strong>Step 4: Validate Against the SI-Projection</strong></h4>
<ul>
<li>Compare the alternative projection with the SI-projection to ensure it aligns with the expected motion.</li>
</ul>
<hr />
<h3 id="3-application-examples"><strong>3. Application Examples</strong></h3>
<h4 id="example-1-detecting-horizontal-saccades"><strong>Example 1: Detecting Horizontal Saccades</strong></h4>
<ul>
<li>Aggregate signal along the <strong>LR-axis</strong> to compute the horizontal projection.</li>
<li>Analyze the projection for abrupt changes indicating rapid eye shifts (saccades).</li>
</ul>
<h4 id="example-2-custom-projection-for-diagonal-motion"><strong>Example 2: Custom Projection for Diagonal Motion</strong></h4>
<ul>
<li>If the motion does not align with standard anatomical axes, project the data along an oblique axis.</li>
<li>Define the oblique axis as a linear combination of standard axes:
    <code>python
    oblique_projection = np.sum(raw_data[:, :, :] * weight_matrix, axis=1)</code></li>
<li>Here, <code>weight_matrix</code> defines the contribution of each axis to the oblique direction.</li>
</ul>
<hr />
<h3 id="4-considerations-for-projections"><strong>4. Considerations for Projections</strong></h3>
<h4 id="signal-to-noise-ratio-snr"><strong>Signal-to-Noise Ratio (SNR)</strong></h4>
<ul>
<li>The effectiveness of the projection depends on the SNR of the data along the chosen axis.</li>
<li>Ensure the data is preprocessed to remove noise that could obscure motion-related signals.</li>
</ul>
<h4 id="sensitivity-to-artifacts"><strong>Sensitivity to Artifacts</strong></h4>
<ul>
<li>Motion unrelated to the chosen axis (e.g., respiration or scanner vibrations) might still appear in the projection. Combining multiple projections can help differentiate these artifacts.</li>
</ul>
<h4 id="validation-with-ground-truth"><strong>Validation with Ground Truth</strong></h4>
<ul>
<li>If you are analyzing eye motion, consider validating the projections with eye-tracking data or known motion patterns.</li>
</ul>
<hr />
<h3 id="5-practical-code-example"><strong>5. Practical Code Example</strong></h3>
<p>Here’s an example for <strong>horizontal (LR) projection</strong>:</p>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

# Simulated k-space data (replace with actual data)
# Shape: (time_points, x_dim, y_dim, z_dim)
raw_data = np.random.randn(100, 128, 128, 128)

# Aggregate along LR-axis (x-axis)
lr_projection = np.sum(raw_data[:, :, :, :], axis=2)  # Adjust axis to your data structure

# Plot the resulting projection signal over time
plt.plot(np.mean(lr_projection, axis=(1, 2)))  # Time-series of LR-projection signal
plt.title('Left-Right Projection Signal')
plt.xlabel('Time')
plt.ylabel('Signal Intensity')
plt.show()
</code></pre>
<hr />
<h3 id="conclusion_1"><strong>Conclusion</strong></h3>
<ul>
<li>You can compute projections along any desired axis (e.g., LR, AP) to align with the motion of interest.</li>
<li>This flexibility is helpful for studying motion patterns that do not align with the SI-axis.</li>
<li>Combining projections from multiple axes can improve the robustness of motion detection by capturing more dimensions of motion.</li>
</ul></p>
    </article>
</section>
<!-- endblock -->
            </main>

            
                    <!-- block preview -->
        <div class="row row-cols-md-3 text-center pt-md-3" id="component-preview">
            <div class="col themed-grid-col">
                <a rel="prev" href="../papers/SISMIK_for_brain_MRI/" class="nav-link">
                    <i class="fa fa-arrow-left"></i> Previous
                </a>
            </div>
            <div class="col themed-grid-col"></div>
            <div class="col themed-grid-col">
                <a rel="next" class="nav-link disabled">
                    Next <i class="fa fa-arrow-right"></i>
                </a>
            </div>
        </div>
<!-- endblock -->
            

            
                    <!-- block footer -->
<footer class="pt-4 my-md-5 pt-md-5 border-top" id="component-footer">
    <div class="row">
        <div class="col-12 col-md">
                <!-- block copyright -->

    <small class="d-block mb-3">
        Made with
        <a href="https://github.com/FernandoCelmer/mkdocs-simple-blog" target="_blank" rel="noopener">
            Simple Blog for MkDocs
        </a>
    </small>

<!-- endblock -->
        </div>
    </div>
</footer>
<!-- endblock -->
            
        </div>

            <script>var base_url = '../..';</script>
            <script src="../../assets/js/jquery-3.3.1.slim.min.js""></script>
            <script src="../../assets/js/bootstrap.bundle.min.js""></script>
            <script src="../../assets/js/main.min.js""></script>
                <script src="../../search/main.js" defer></script>

    </body>

</html>